//package content.ecosystem.http4k.reference.model_context_protocol
//
//import org.http4k.ai.mcp.IncomingSamplingHandler
//import org.http4k.ai.mcp.SamplingRequest
//import org.http4k.ai.mcp.SamplingResponse
//import org.http4k.ai.mcp.model.Content
//import org.http4k.ai.mcp.model.MaxTokens
//import org.http4k.ai.mcp.model.Message
//import org.http4k.ai.mcp.model.ModelIdentifier
//import org.http4k.ai.mcp.model.ModelPreferences
//import org.http4k.ai.mcp.model.ModelScore
//import org.http4k.ai.mcp.model.ModelSelector
//import org.http4k.ai.mcp.model.Role.assistant
//import org.http4k.ai.mcp.model.Role.user
//import org.http4k.ai.mcp.model.StopReason
//
//object SampleFromOurLocalLlm {
//
//    // the name of our model
//    val llmName = ModelIdentifier.of("my-llm")
//
//    // the selector of the model - you can pass a function to score the model
//    val selector = ModelSelector(llmName) { prefs: ModelPreferences ->
//        ModelScore.of(1.0)
//    }
//
//    // this function provides sampling options for the "my-llm" model, returning a list of response
//    // messages generated by the server
//    val handler: IncomingSamplingHandler = {
//        listOf(
//            SamplingResponse(
//                llmName,
//                assistant,
//                Content.Text("The first message generated by the server")
//            ),
//            SamplingResponse(
//                llmName,
//                assistant,
//                Content.Text("The last message generated by the server"),
//                StopReason.of("end") // this is the last message
//            )
//        ).asSequence()
//    }
//}
//
//// invoke/test the prompt offline - just invoke it like a function
//fun main() =
//    println(
//        SampleFromOurLocalLlm.handler(
//            SamplingRequest(
//                listOf(
//                    Message(user, Content.Text("Make me a sandwich!")),
//                    Message(assistant, Content.Text("You do not have the necessary authority.")),
//                    Message(user, Content.Text("Sudo make me a sandwich!")),
//                ), MaxTokens.of(123123)
//            )
//        ).toList().joinToString("\n")
//    )
